{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST INT8 Classification on ESP32-P4 using P4-JIT\n",
    "\n",
    "## ✅ Complete Fixed Pipeline\n",
    "\n",
    "**Key Fixes:**\n",
    "- ✅ **Correct bias scaling**: `bias × 2^E_in` (not `2^(E_in+E_w-E_out)`)\n",
    "- ✅ **Input quantization** from the start\n",
    "- ✅ **Proper preprocessing** match between training and deployment\n",
    "- ✅ **Individual scale exponents** passed to C for clarity\n",
    "- ✅ **Smart Args** for clean NumPy interface\n",
    "- ✅ **Verification steps** at each stage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment ready\n",
      "✓ PyTorch: 2.8.0+cu126\n",
      "✓ Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# Setup directories\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "SOURCE_DIR = NOTEBOOK_DIR / \"source\"\n",
    "WEIGHTS_DIR = NOTEBOOK_DIR / \"weights\"\n",
    "RESULTS_DIR = NOTEBOOK_DIR / \"results\"\n",
    "\n",
    "for d in [SOURCE_DIR, WEIGHTS_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add P4-JIT\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent.parent\n",
    "sys.path.append(str(PROJECT_ROOT / \"host\"))\n",
    "\n",
    "from p4jit import P4JIT, MALLOC_CAP_SPIRAM, MALLOC_CAP_8BIT\n",
    "import p4jit\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Environment ready\")\n",
    "print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "print(f\"✓ Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "**Important:** MNIST images are normalized with `mean=0.1307, std=0.3081` during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"✓ Train: {len(train_dataset):,} | Test: {len(test_dataset):,}\")\n",
    "\n",
    "# Visualize (denormalized for display)\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "for i in range(20):\n",
    "    img, label = train_dataset[i]\n",
    "    # Denormalize for visualization\n",
    "    img_display = img.squeeze() * 0.3081 + 0.1307\n",
    "    ax = axes[i // 10, i % 10]\n",
    "    ax.imshow(img_display, cmap='gray')\n",
    "    ax.set_title(f'{label}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('MNIST Dataset Samples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'dataset.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantization Modules\n",
    "\n",
    "**Power-of-2 scales** with Straight-Through Estimator for gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Quantization modules defined\n"
     ]
    }
   ],
   "source": [
    "class PowerOfTwoQuantize(torch.autograd.Function):\n",
    "    \"\"\"INT8 quantization with Straight-Through Estimator\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, scale_exp):\n",
    "        scale = 2.0 ** scale_exp\n",
    "        x_q = torch.clamp(torch.round(x * scale), -128, 127)\n",
    "        x_dq = x_q / scale\n",
    "        return x_dq\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None\n",
    "\n",
    "\n",
    "class FakeQuantizeINT8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer('scale_exp', torch.tensor(0))\n",
    "        self.enabled = False\n",
    "        \n",
    "    def set_scale_exp(self, exp):\n",
    "        self.scale_exp = torch.tensor(exp)\n",
    "        \n",
    "    def enable(self):\n",
    "        self.enabled = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.enabled:\n",
    "            return x\n",
    "        return PowerOfTwoQuantize.apply(x, self.scale_exp)\n",
    "    \n",
    "    def get_scale_info(self):\n",
    "        exp = int(self.scale_exp.item())\n",
    "        scale = 2.0 ** (-exp)\n",
    "        return exp, scale\n",
    "\n",
    "\n",
    "class QuantizedConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.weight_quant = FakeQuantizeINT8()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        w_q = self.weight_quant(self.conv.weight)\n",
    "        return F.conv2d(x, w_q, self.conv.bias, \n",
    "                       self.conv.stride, self.conv.padding, \n",
    "                       self.conv.dilation, self.conv.groups)\n",
    "\n",
    "\n",
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.weight_quant = FakeQuantizeINT8()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        w_q = self.weight_quant(self.linear.weight)\n",
    "        return F.linear(x, w_q, self.linear.bias)\n",
    "\n",
    "\n",
    "print(\"✓ Quantization modules defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "**With input quantization from the start!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model: 206,922 parameters\n",
      "✓ Input quantization: ENABLED\n",
      "QuantizedMNISTNet(\n",
      "  (input_quant): FakeQuantizeINT8()\n",
      "  (conv1): QuantizedConv2d(\n",
      "    (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (weight_quant): FakeQuantizeINT8()\n",
      "  )\n",
      "  (act1_quant): FakeQuantizeINT8()\n",
      "  (conv2): QuantizedConv2d(\n",
      "    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (weight_quant): FakeQuantizeINT8()\n",
      "  )\n",
      "  (act2_quant): FakeQuantizeINT8()\n",
      "  (fc1): QuantizedLinear(\n",
      "    (linear): Linear(in_features=1568, out_features=128, bias=True)\n",
      "    (weight_quant): FakeQuantizeINT8()\n",
      "  )\n",
      "  (act3_quant): FakeQuantizeINT8()\n",
      "  (fc2): QuantizedLinear(\n",
      "    (linear): Linear(in_features=128, out_features=10, bias=True)\n",
      "    (weight_quant): FakeQuantizeINT8()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class QuantizedMNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input quantization\n",
    "        self.input_quant = FakeQuantizeINT8()\n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = QuantizedConv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.act1_quant = FakeQuantizeINT8()\n",
    "        \n",
    "        self.conv2 = QuantizedConv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.act2_quant = FakeQuantizeINT8()\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = QuantizedLinear(32 * 7 * 7, 128)\n",
    "        self.act3_quant = FakeQuantizeINT8()\n",
    "        \n",
    "        self.fc2 = QuantizedLinear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_quant(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.act1_quant(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.act2_quant(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.act3_quant(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = QuantizedMNISTNet().to(device)\n",
    "\n",
    "print(f\"✓ Model: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\"✓ Input quantization: ENABLED\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training: Warmup → Calibration → QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 1: WARMUP (FP32)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae4e5f7e8d6481a88550b3be17ae1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train: 93.78% | Test: 98.31%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208fe1e24e9148fdade10bca2eb1a6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train: 98.17% | Test: 98.48%\n",
      "✓ Warmup complete: 98.48%\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for data, target in tqdm(loader, desc='Training', leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += output.argmax(dim=1).eq(target).sum().item()\n",
    "    return total_loss / len(loader), 100. * correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            correct += output.argmax(dim=1).eq(target).sum().item()\n",
    "    return total_loss / len(loader), 100. * correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "WARMUP_EPOCHS = 2\n",
    "QAT_EPOCHS = 2\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "# Phase 1: Warmup\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1: WARMUP (FP32)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(1, WARMUP_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{WARMUP_EPOCHS} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}%\")\n",
    "\n",
    "print(f\"✓ Warmup complete: {history['test_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 2: CALIBRATION\n",
      "================================================================================\n",
      "\n",
      "Weight calibration:\n",
      "  conv1                → Exp:  +7 (scale: 2^7)\n",
      "  conv2                → Exp:  +8 (scale: 2^8)\n",
      "  fc1                  → Exp:  +9 (scale: 2^9)\n",
      "  fc2                  → Exp:  +9 (scale: 2^9)\n",
      "\n",
      "Activation calibration:\n",
      "  input_quant          → Exp:  +5 (scale: 2^5)\n",
      "  act1_quant           → Exp:  +4 (scale: 2^4)\n",
      "  act2_quant           → Exp:  +4 (scale: 2^4)\n",
      "  act3_quant           → Exp:  +2 (scale: 2^2)\n",
      "\n",
      "✓ Calibration complete\n"
     ]
    }
   ],
   "source": [
    "def calculate_scale_exponent(tensor):\n",
    "    max_val = tensor.abs().max().item()\n",
    "    if max_val == 0:\n",
    "        return 0\n",
    "    import math\n",
    "    return math.floor(math.log2(127.0 / max_val))\n",
    "\n",
    "\n",
    "def calibrate_activations(model, loader, device, num_batches=10):\n",
    "    model.eval()\n",
    "    activation_stats = {}\n",
    "    \n",
    "    def get_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            if name not in activation_stats:\n",
    "                activation_stats[name] = []\n",
    "            activation_stats[name].append(output.abs().max().item())\n",
    "        return hook\n",
    "    \n",
    "    hooks = []\n",
    "    \n",
    "    # Hook for input\n",
    "    def input_hook(module, input):\n",
    "        if 'input_quant' not in activation_stats:\n",
    "            activation_stats['input_quant'] = []\n",
    "        activation_stats['input_quant'].append(input[0].abs().max().item())\n",
    "    \n",
    "    hooks.append(model.register_forward_pre_hook(input_hook))\n",
    "    \n",
    "    # Hooks for activations\n",
    "    for name, module in model.named_modules():\n",
    "        if 'act' in name and isinstance(module, FakeQuantizeINT8):\n",
    "            parent_name = '.'.join(name.split('.')[:-1])\n",
    "            if parent_name:\n",
    "                parent = dict(model.named_modules())[parent_name]\n",
    "            else:\n",
    "                parent = module\n",
    "            hooks.append(parent.register_forward_hook(get_hook(name)))\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            model(data.to(device))\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    exponents = {}\n",
    "    for name, values in activation_stats.items():\n",
    "        max_val = max(values)\n",
    "        import math\n",
    "        exp = math.floor(math.log2(127.0 / max_val)) if max_val > 0 else 0\n",
    "        exponents[name] = exp\n",
    "    \n",
    "    return exponents\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2: CALIBRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Weights\n",
    "print(\"\\nWeight calibration:\")\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (QuantizedConv2d, QuantizedLinear)):\n",
    "        weight = module.conv.weight if isinstance(module, QuantizedConv2d) else module.linear.weight\n",
    "        exp = calculate_scale_exponent(weight.data)\n",
    "        module.weight_quant.set_scale_exp(exp)\n",
    "        print(f\"  {name:20s} → Exp: {exp:+3d} (scale: 2^{exp})\")\n",
    "\n",
    "# Activations\n",
    "print(\"\\nActivation calibration:\")\n",
    "act_exponents = calibrate_activations(model, train_loader, device, num_batches=10)\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, FakeQuantizeINT8) and name in act_exponents:\n",
    "        exp = act_exponents[name]\n",
    "        module.set_scale_exp(exp)\n",
    "        print(f\"  {name:20s} → Exp: {exp:+3d} (scale: 2^{exp})\")\n",
    "\n",
    "print(\"\\n✓ Calibration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAT Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 3: QUANTIZATION-AWARE TRAINING\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdf778814224d16ac11bde2a00df92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 | Train: 98.87% | Test: 98.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc511cb6064e4bd590f2bbfb85a05645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 | Train: 99.10% | Test: 98.73%\n",
      "\n",
      "================================================================================\n",
      "✓ Final Test Accuracy: 98.73%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Enable quantization\n",
    "for module in model.modules():\n",
    "    if isinstance(module, FakeQuantizeINT8):\n",
    "        module.enable()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 3: QUANTIZATION-AWARE TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "for epoch in range(1, QAT_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    total_epoch = WARMUP_EPOCHS + epoch\n",
    "    print(f\"Epoch {total_epoch}/{WARMUP_EPOCHS + QAT_EPOCHS} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✓ Final Test Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Quantized Weights\n",
    "\n",
    "**Store all scale exponents for C code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "WEIGHT EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "Input: E_in = 5\n",
      "Conv1: E_w= +7, E_act= +4, W_shape=(16, 1, 3, 3)\n",
      "Conv2: E_w= +8, E_act= +4, W_shape=(32, 16, 3, 3)\n",
      "FC1:   E_w= +9, E_act= +2, W_shape=(128, 1568)\n",
      "FC2:   E_w= +9, W_shape=(10, 128)\n",
      "\n",
      "✓ Total: 206,922 bytes (202.07 KB)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def quantize_to_int8(tensor, scale_exp):\n",
    "    scale = 2.0 ** scale_exp\n",
    "    quantized = torch.clamp(torch.round(tensor * scale), -128, 127).to(torch.int8)\n",
    "    return quantized.cpu().numpy()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "quantized_weights = {}\n",
    "scale_exponents = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEIGHT EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Input\n",
    "input_exp, _ = model.input_quant.get_scale_info()\n",
    "scale_exponents['input'] = input_exp\n",
    "print(f\"\\nInput: E_in = {input_exp}\")\n",
    "\n",
    "# Conv1\n",
    "w_exp, _ = model.conv1.weight_quant.get_scale_info()\n",
    "act_exp, _ = model.act1_quant.get_scale_info()\n",
    "w = quantize_to_int8(model.conv1.conv.weight.data, w_exp)\n",
    "b = quantize_to_int8(model.conv1.conv.bias.data, w_exp)\n",
    "quantized_weights['conv1'] = {'weight': w, 'bias': b}\n",
    "scale_exponents['conv1'] = {'w': w_exp, 'act': act_exp}\n",
    "print(f\"Conv1: E_w={w_exp:+3d}, E_act={act_exp:+3d}, W_shape={w.shape}\")\n",
    "\n",
    "# Conv2\n",
    "w_exp, _ = model.conv2.weight_quant.get_scale_info()\n",
    "act_exp, _ = model.act2_quant.get_scale_info()\n",
    "w = quantize_to_int8(model.conv2.conv.weight.data, w_exp)\n",
    "b = quantize_to_int8(model.conv2.conv.bias.data, w_exp)\n",
    "quantized_weights['conv2'] = {'weight': w, 'bias': b}\n",
    "scale_exponents['conv2'] = {'w': w_exp, 'act': act_exp}\n",
    "print(f\"Conv2: E_w={w_exp:+3d}, E_act={act_exp:+3d}, W_shape={w.shape}\")\n",
    "\n",
    "# FC1\n",
    "w_exp, _ = model.fc1.weight_quant.get_scale_info()\n",
    "act_exp, _ = model.act3_quant.get_scale_info()\n",
    "w = quantize_to_int8(model.fc1.linear.weight.data, w_exp)\n",
    "b = quantize_to_int8(model.fc1.linear.bias.data, w_exp)\n",
    "quantized_weights['fc1'] = {'weight': w, 'bias': b}\n",
    "scale_exponents['fc1'] = {'w': w_exp, 'act': act_exp}\n",
    "print(f\"FC1:   E_w={w_exp:+3d}, E_act={act_exp:+3d}, W_shape={w.shape}\")\n",
    "\n",
    "# FC2\n",
    "w_exp, _ = model.fc2.weight_quant.get_scale_info()\n",
    "w = quantize_to_int8(model.fc2.linear.weight.data, w_exp)\n",
    "b = quantize_to_int8(model.fc2.linear.bias.data, w_exp)\n",
    "quantized_weights['fc2'] = {'weight': w, 'bias': b}\n",
    "scale_exponents['fc2'] = {'w': w_exp}\n",
    "print(f\"FC2:   E_w={w_exp:+3d}, W_shape={w.shape}\")\n",
    "\n",
    "total_params = sum(w['weight'].size + w['bias'].size for w in quantized_weights.values())\n",
    "print(f\"\\n✓ Total: {total_params:,} bytes ({total_params/1024:.2f} KB)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. C Implementation with FIXED Bias Scaling\n",
    "\n",
    "### The Correct Math:\n",
    "\n",
    "```\n",
    "Accumulator = Σ(input_q × weight_q)\n",
    "            = Σ((input × 2^E_in) × (weight × 2^E_w))\n",
    "            = (Σ input × weight) × 2^(E_in + E_w)\n",
    "\n",
    "Bias at scale 2^E_w needs to be brought to scale 2^(E_in + E_w):\n",
    "  bias_scaled = bias_q × 2^E_in\n",
    "\n",
    "Then scale to output:\n",
    "  output_q = (acc + bias_scaled) >> (E_in + E_w - E_out)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ C code saved: c:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\notebooks\\tutorials\\t02_mnist_classification\\source\\mnist_inference.c\n",
      "✓ Size: 7967 bytes\n",
      "✓ FIX 1: ReLU applied BEFORE quantization\n",
      "✓ FIX 2: FC2 outputs INT32 logits\n",
      "✓ NEW: Cycle counter timing added\n"
     ]
    }
   ],
   "source": [
    "c_code = \"\"\"#include <stdint.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// Read RISC-V cycle counter\n",
    "static inline uint32_t rdcycle(void) {\n",
    "    uint32_t cycles;\n",
    "    asm volatile (\"rdcycle %0\" : \"=r\"(cycles));\n",
    "    return cycles;\n",
    "}\n",
    "\n",
    "static inline int32_t relu_int32(int32_t x) { return (x > 0) ? x : 0; }\n",
    "static inline int8_t clip_int8(int32_t x) {\n",
    "    return (x > 127) ? 127 : ((x < -128) ? -128 : (int8_t)x);\n",
    "}\n",
    "\n",
    "// Conv2d with ReLU BEFORE quantization\n",
    "void conv2d_int8(\n",
    "    const int8_t* input, int in_h, int in_w, int in_c,\n",
    "    const int8_t* weight, const int8_t* bias,\n",
    "    int8_t* output, int out_c,\n",
    "    int exp_in, int exp_w, int exp_out\n",
    ") {\n",
    "    const int K = 3, P = 1, S = 1;\n",
    "    int out_h = (in_h + 2*P - K) / S + 1;\n",
    "    int out_w = (in_w + 2*P - K) / S + 1;\n",
    "    \n",
    "    int acc_shift = exp_in + exp_w - exp_out;\n",
    "    \n",
    "    for (int oc = 0; oc < out_c; oc++) {\n",
    "        for (int oh = 0; oh < out_h; oh++) {\n",
    "            for (int ow = 0; ow < out_w; ow++) {\n",
    "                int32_t acc = 0;\n",
    "                \n",
    "                // MAC\n",
    "                for (int ic = 0; ic < in_c; ic++) {\n",
    "                    for (int kh = 0; kh < K; kh++) {\n",
    "                        for (int kw = 0; kw < K; kw++) {\n",
    "                            int ih = oh * S - P + kh;\n",
    "                            int iw = ow * S - P + kw;\n",
    "                            \n",
    "                            if (ih >= 0 && ih < in_h && iw >= 0 && iw < in_w) {\n",
    "                                acc += (int32_t)input[(ic * in_h + ih) * in_w + iw] *\n",
    "                                       (int32_t)weight[((oc * in_c + ic) * K + kh) * K + kw];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                // Add bias (scaled by E_in)\n",
    "                acc += (int32_t)bias[oc] << exp_in;\n",
    "                \n",
    "                // ReLU BEFORE quantization\n",
    "                acc = relu_int32(acc);\n",
    "                \n",
    "                // Scale to output\n",
    "                acc = acc >> acc_shift;\n",
    "                \n",
    "                output[(oc * out_h + oh) * out_w + ow] = clip_int8(acc);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void maxpool2d_int8(const int8_t* input, int8_t* output, int h, int w, int c) {\n",
    "    int out_h = h / 2, out_w = w / 2;\n",
    "    for (int ch = 0; ch < c; ch++) {\n",
    "        for (int oh = 0; oh < out_h; oh++) {\n",
    "            for (int ow = 0; ow < out_w; ow++) {\n",
    "                int8_t max_val = -128;\n",
    "                for (int kh = 0; kh < 2; kh++) {\n",
    "                    for (int kw = 0; kw < 2; kw++) {\n",
    "                        int8_t v = input[(ch * h + oh*2 + kh) * w + ow*2 + kw];\n",
    "                        if (v > max_val) max_val = v;\n",
    "                    }\n",
    "                }\n",
    "                output[(ch * out_h + oh) * out_w + ow] = max_val;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// FC layer with ReLU BEFORE quantization\n",
    "void fc_int8(\n",
    "    const int8_t* input, int in_size,\n",
    "    const int8_t* weight, const int8_t* bias,\n",
    "    int8_t* output, int out_size,\n",
    "    int exp_in, int exp_w, int exp_out\n",
    ") {\n",
    "    int acc_shift = exp_in + exp_w - exp_out;\n",
    "    \n",
    "    for (int i = 0; i < out_size; i++) {\n",
    "        int32_t acc = 0;\n",
    "        for (int j = 0; j < in_size; j++) {\n",
    "            acc += (int32_t)input[j] * (int32_t)weight[i * in_size + j];\n",
    "        }\n",
    "        \n",
    "        // Add bias (scaled by E_in)\n",
    "        acc += (int32_t)bias[i] << exp_in;\n",
    "        \n",
    "        // ReLU BEFORE quantization\n",
    "        acc = relu_int32(acc);\n",
    "        \n",
    "        // Scale to output\n",
    "        acc = acc >> acc_shift;\n",
    "        \n",
    "        output[i] = clip_int8(acc);\n",
    "    }\n",
    "}\n",
    "\n",
    "// FC layer WITHOUT quantization (for final layer)\n",
    "void fc_int32(\n",
    "    const int8_t* input, int in_size,\n",
    "    const int8_t* weight, const int8_t* bias,\n",
    "    int32_t* output, int out_size,\n",
    "    int exp_in, int exp_w\n",
    ") {\n",
    "    for (int i = 0; i < out_size; i++) {\n",
    "        int32_t acc = 0;\n",
    "        for (int j = 0; j < in_size; j++) {\n",
    "            acc += (int32_t)input[j] * (int32_t)weight[i * in_size + j];\n",
    "        }\n",
    "        \n",
    "        // Add bias (scaled by E_in)\n",
    "        acc += (int32_t)bias[i] << exp_in;\n",
    "        \n",
    "        // NO ReLU, NO quantization - raw logits\n",
    "        output[i] = acc;\n",
    "    }\n",
    "}\n",
    "\n",
    "void fc_int32_p4simd(\n",
    "    const int8_t* input, int in_size,\n",
    "    const int8_t* weight, const int8_t* bias,\n",
    "    int32_t* output, int out_size,\n",
    "    int exp_in, int exp_w\n",
    ") {\n",
    "    // Current pointer to weights (increments monotonically)\n",
    "    const int8_t* w_ptr = weight;\n",
    "    \n",
    "    // Calculate loop iterations (16 bytes per iteration)\n",
    "    int loop_count = in_size >> 4; \n",
    "\n",
    "    for (int i = 0; i < out_size; i++) {\n",
    "        const int8_t* in_ptr = input;\n",
    "        int32_t acc_val;\n",
    "        int shift_amt = 0; // Shift amount for result extraction\n",
    "\n",
    "        asm volatile (\n",
    "            \"esp.zero.accx \\\\n\\\\t\"                  // Clear accumulator\n",
    "            \"lp.setup 0, %[cnt], 1f \\\\n\\\\t\"         // Setup HW loop 0\n",
    "            \"lp.start 0 \\\\n\\\\t\"                     // Start HW loop 0\n",
    "            \"0: \\\\n\\\\t\"                             // Loop body start label\n",
    "            \"esp.vld.128.ip q0, %[in], 16 \\\\n\\\\t\"   // Load 16 inputs, ptr+=16\n",
    "            \"esp.vld.128.ip q1, %[w], 16 \\\\n\\\\t\"    // Load 16 weights, ptr+=16\n",
    "            \"esp.vmulas.s8.accx q0, q1 \\\\n\\\\t\"      // Multiply & Accumulate\n",
    "            \"1: \\\\n\\\\t\"                             // Loop end label\n",
    "            \"esp.srs.accx %[res], %[shft], 0 \\\\n\\\\t\" // Extract result to GPR\n",
    "\n",
    "            // Output Operands\n",
    "            : [res] \"=r\" (acc_val),       // Output: Result value\n",
    "              [in]  \"+r\" (in_ptr),        // Read/Write: Input pointer\n",
    "              [w]   \"+r\" (w_ptr)          // Read/Write: Weight pointer\n",
    "            \n",
    "            // Input Operands\n",
    "            : [cnt] \"r\" (loop_count),     // Input: Loop count\n",
    "              [shft] \"r\" (shift_amt)      // Input: Shift amount (0)\n",
    "            \n",
    "            // Clobbers\n",
    "            : \"memory\"\n",
    "        );\n",
    "\n",
    "        // Post-processing: Add bias and scale (Scalar operations)\n",
    "        output[i] = acc_val + ((int32_t)bias[i] << exp_in);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Inference function WITH TIMING\n",
    "int32_t mnist_inference(\n",
    "    int8_t* input,\n",
    "    int8_t* w_conv1, int8_t* b_conv1,\n",
    "    int8_t* w_conv2, int8_t* b_conv2,\n",
    "    int8_t* w_fc1, int8_t* b_fc1,\n",
    "    int8_t* w_fc2, int8_t* b_fc2,\n",
    "    int32_t e_in,\n",
    "    int32_t e_conv1_w, int32_t e_conv1_act,\n",
    "    int32_t e_conv2_w, int32_t e_conv2_act,\n",
    "    int32_t e_fc1_w, int32_t e_fc1_act,\n",
    "    int32_t e_fc2_w,\n",
    "    int8_t* scratch,\n",
    "    uint32_t* timing  \n",
    ") {\n",
    "    // Start timing\n",
    "    uint32_t start_cycles = rdcycle();\n",
    "    \n",
    "    printf(\"[JIT] Inference start\\\\n\");\n",
    "    \n",
    "    int8_t* conv1_out = scratch;\n",
    "    int8_t* pool1_out = conv1_out + 16*28*28;\n",
    "    int8_t* conv2_out = pool1_out + 16*14*14;\n",
    "    int8_t* pool2_out = conv2_out + 32*14*14;\n",
    "    int8_t* fc1_out = pool2_out + 32*7*7;\n",
    "    \n",
    "    // Allocate INT32 buffer for final logits\n",
    "    int32_t* fc2_out = (int32_t*)(fc1_out + 128);\n",
    "    \n",
    "    // Conv1 + ReLU + MaxPool\n",
    "    conv2d_int8(input, 28, 28, 1, w_conv1, b_conv1, conv1_out, 16, \n",
    "                e_in, e_conv1_w, e_conv1_act);\n",
    "    maxpool2d_int8(conv1_out, pool1_out, 28, 28, 16);\n",
    "    \n",
    "    // Conv2 + ReLU + MaxPool\n",
    "    conv2d_int8(pool1_out, 14, 14, 16, w_conv2, b_conv2, conv2_out, 32,\n",
    "                e_conv1_act, e_conv2_w, e_conv2_act);\n",
    "    maxpool2d_int8(conv2_out, pool2_out, 14, 14, 32);\n",
    "    \n",
    "    // FC1 + ReLU\n",
    "    fc_int8(pool2_out, 1568, w_fc1, b_fc1, fc1_out, 128,\n",
    "            e_conv2_act, e_fc1_w, e_fc1_act);\n",
    "    \n",
    "    // FC2 → INT32 logits\n",
    "    fc_int32_p4simd(fc1_out, 128, w_fc2, b_fc2, fc2_out, 10,\n",
    "             e_fc1_act, e_fc2_w);\n",
    "    \n",
    "    // End timing\n",
    "    uint32_t end_cycles = rdcycle();\n",
    "    uint32_t elapsed = end_cycles - start_cycles;\n",
    "    \n",
    "    // Store timing in output array\n",
    "    timing[0] = elapsed;\n",
    "    \n",
    "    // Argmax\n",
    "    int32_t max_val = fc2_out[0];\n",
    "    int32_t max_idx = 0;\n",
    "    for (int i = 1; i < 10; i++) {\n",
    "        if (fc2_out[i] > max_val) {\n",
    "            max_val = fc2_out[i];\n",
    "            max_idx = i;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    printf(\"[JIT] Predicted: %d (logit: %d) | Cycles: %u\\\\n\", max_idx, max_val, elapsed);\n",
    "    return max_idx;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "c_path = SOURCE_DIR / \"mnist_inference.c\"\n",
    "with open(c_path, 'w') as f:\n",
    "    f.write(c_code)\n",
    "\n",
    "print(f\"✓ C code saved: {c_path}\")\n",
    "print(f\"✓ Size: {len(c_code)} bytes\")\n",
    "print(\"✓ FIX 1: ReLU applied BEFORE quantization\")\n",
    "print(\"✓ FIX 2: FC2 outputs INT32 logits\")\n",
    "print(\"✓ NEW: Cycle counter timing added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prepare Test Images\n",
    "\n",
    "**Match preprocessing from training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_raw = {}\n",
    "test_images_int8 = {}\n",
    "\n",
    "input_exp = scale_exponents['input']\n",
    "input_scale = 2.0 ** input_exp\n",
    "\n",
    "for digit in range(10):\n",
    "    for img, label in test_dataset:\n",
    "        if label == digit:\n",
    "            test_images_raw[digit] = img\n",
    "            \n",
    "            # Quantize NORMALIZED image (matching training)\n",
    "            img_np = img.squeeze().numpy()  # Already normalized!\n",
    "            img_int8 = np.clip(np.round(img_np * input_scale), -128, 127).astype(np.int8)\n",
    "            test_images_int8[digit] = img_int8.flatten()\n",
    "            break\n",
    "\n",
    "print(f\"✓ Test images prepared\")\n",
    "print(f\"  Input scale: 2^{input_exp} = {input_scale}\")\n",
    "print(f\"  Range: [{test_images_int8[0].min()}, {test_images_int8[0].max()}]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for digit in range(10):\n",
    "    ax = axes[digit // 5, digit % 5]\n",
    "    # Denormalize for display\n",
    "    img_display = test_images_raw[digit].squeeze() * 0.3081 + 0.1307\n",
    "    ax.imshow(img_display, cmap='gray')\n",
    "    ax.set_title(f'Digit {digit}', fontweight='bold')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Test Images', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'test_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy to ESP32-P4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ESP32-P4 DEPLOYMENT\n",
      "================================================================================\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m: Initializing P4JIT System...\n",
      "12:58:42 [p4jit.runtime.jit_session] \u001b[94mINFO\u001b[0m: Auto-detecting JIT device...\n",
      "12:58:42 [p4jit.runtime.device_manager] \u001b[94mINFO\u001b[0m: Connecting to COM3 at 115200 baud...\n",
      "12:58:42 [p4jit.runtime.device_manager] \u001b[94mINFO\u001b[0m: Connecting to COM6 at 115200 baud...\n",
      "12:58:42 [p4jit.runtime.device_manager] \u001b[94mINFO\u001b[0m: Connected.\n",
      "12:58:42 [p4jit.runtime.jit_session] \u001b[94mINFO\u001b[0m: Found JIT Device at COM6\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m: P4JIT Initialized.\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m: [Heap Params]\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m:   free_spiram    :   31388992 bytes (30653.31 KB)\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m:   total_spiram   :   33554432 bytes (32768.00 KB)\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m:   free_internal  :     384063 bytes (375.06 KB)\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m:   total_internal :     464119 bytes (453.24 KB)\n",
      "\n",
      "Compiling kernel...\n",
      "12:58:42 [p4jit.p4jit] \u001b[94mINFO\u001b[0m: Loading 'mnist_inference' from 'mnist_inference.c'...\n",
      "12:58:42 [p4jit.toolchain.wrapper_builder] \u001b[94mINFO\u001b[0m: Generating wrapper for 'mnist_inference'\n",
      "12:58:42 [p4jit.toolchain.wrapper_builder] \u001b[94mINFO\u001b[0m: Building wrapper binary...\n",
      "12:58:42 [p4jit.toolchain.builder] \u001b[94mINFO\u001b[0m: Discovered 2 source file(s) in c:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\notebooks\\tutorials\\t02_mnist_classification\\source\n",
      "12:58:43 [p4jit.toolchain.compiler] \u001b[91mERROR\u001b[0m: Linking failed:\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c: Assembler messages:\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a6,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\n",
      "c:Usersoranilelgit_projects\n",
      "obert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\n",
      "otebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a3,a2,0'\n",
      "lto-wrapper.exe: fatal error: C:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin\\riscv32-esp-elf-gcc returned 1 exit status\n",
      "compilation terminated.\n",
      "C:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin/../lib/gcc/riscv32-esp-elf/14.2.0/../../../../riscv32-esp-elf/bin/ld.exe: error: lto-wrapper failed\n",
      "collect2.exe: error: ld returned 1 exit status\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Linking failed:\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c: Assembler messages:\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a6,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a3,a2,0'\nlto-wrapper.exe: fatal error: C:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin\\riscv32-esp-elf-gcc returned 1 exit status\ncompilation terminated.\nC:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin/../lib/gcc/riscv32-esp-elf/14.2.0/../../../../riscv32-esp-elf/bin/ld.exe: error: lto-wrapper failed\ncollect2.exe: error: ld returned 1 exit status\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompiling kernel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m p4jit\u001b[38;5;241m.\u001b[39mset_log_level(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_inference\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mO3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_firmware_elf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmart_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Loaded at: 0x\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39mcode_addr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m08X\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Binary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m KB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\host\\p4jit\\p4jit.py:152\u001b[0m, in \u001b[0;36mP4JIT.load\u001b[1;34m(self, source, function_name, base_address, arg_address, optimization, output_dir, use_firmware_elf, code_caps, data_caps, alignment, smart_args)\u001b[0m\n\u001b[0;32m    149\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(INFO_VERBOSE, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass 1: Preliminary Build (Opt: -\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Pass 1: Build with default/requested addresses to get size\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m temp_bin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_with_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_firmware_elf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_firmware_elf\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# 2. Allocate\u001b[39;00m\n\u001b[0;32m    162\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(INFO_VERBOSE, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllocating device memory (Align: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malignment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\host\\p4jit\\toolchain\\wrapper_builder.py:91\u001b[0m, in \u001b[0;36mWrapperBuilder.build_with_wrapper\u001b[1;34m(self, source, function_name, base_address, arg_address, output_dir, use_firmware_elf)\u001b[0m\n\u001b[0;32m     88\u001b[0m wrapper_entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrapper\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrapper_entry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     90\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding wrapper binary...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m binary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_c_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapper_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_firmware_elf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_firmware_elf\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Generate metadata\u001b[39;00m\n\u001b[0;32m     99\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(INFO_VERBOSE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating metadata...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\host\\p4jit\\toolchain\\builder.py:169\u001b[0m, in \u001b[0;36mBuilder.build\u001b[1;34m(self, source, entry_point, base_address, optimization, output_dir, use_firmware_elf)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Link all object files\u001b[39;00m\n\u001b[0;32m    168\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(INFO_VERBOSE, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(obj_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object file(s)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m elf_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinker_script\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_script\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.elf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_firmware_elf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_firmware_elf\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Extract binary\u001b[39;00m\n\u001b[0;32m    177\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(INFO_VERBOSE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting binary...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orani\\bilel\\git_projects\\robert_manzke\\project1\\trys\\costume_p4code_binary\\P4-JIT\\host\\p4jit\\toolchain\\compiler.py:136\u001b[0m, in \u001b[0;36mCompiler.link\u001b[1;34m(self, obj_files, linker_script, output, use_firmware_elf)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinking failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinking failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Linking failed:\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c: Assembler messages:\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a6,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:152: Error: illegal operands `esp.vld.128.ip q0,a6,16'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a7,a2,0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:148: Error: unrecognized opcode `esp.zero.accx'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:149: Error: unrecognized opcode `lp.setup 0,a3,1f'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:150: Error: unrecognized opcode `lp.start 0'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:154: Error: unrecognized opcode `esp.vmulas.s8.accx q0,q1'\nc:Usersorani\bilelgit_projects\nobert_manzkeproject1\tryscostume_p4code_binaryP4-JIT\notebooks\tutorials\t02_mnist_classificationsourcemnist_inference.c:156: Error: unrecognized opcode `esp.srs.accx a3,a2,0'\nlto-wrapper.exe: fatal error: C:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin\\riscv32-esp-elf-gcc returned 1 exit status\ncompilation terminated.\nC:/Espressif/tools/riscv32-esp-elf/esp-14.2.0_20241119/riscv32-esp-elf/bin/../lib/gcc/riscv32-esp-elf/14.2.0/../../../../riscv32-esp-elf/bin/ld.exe: error: lto-wrapper failed\ncollect2.exe: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESP32-P4 DEPLOYMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "jit = P4JIT()\n",
    "stats_initial = jit.get_heap_stats(print_s=True)\n",
    "\n",
    "print(\"\\nCompiling kernel...\")\n",
    "p4jit.set_log_level('INFO')\n",
    "\n",
    "func = jit.load(\n",
    "    source=str(c_path),\n",
    "    function_name='mnist_inference',\n",
    "    optimization='O3',\n",
    "    use_firmware_elf=True,\n",
    "    smart_args=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Loaded at: 0x{func.code_addr:08X}\")\n",
    "print(f\"✓ Binary: {func.stats['code_size']} bytes ({func.stats['code_size']/1024:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INFERENCE ON ESP32-P4\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare exponents\n",
    "e_in = scale_exponents['input']\n",
    "e_conv1_w = scale_exponents['conv1']['w']\n",
    "e_conv1_act = scale_exponents['conv1']['act']\n",
    "e_conv2_w = scale_exponents['conv2']['w']\n",
    "e_conv2_act = scale_exponents['conv2']['act']\n",
    "e_fc1_w = scale_exponents['fc1']['w']\n",
    "e_fc1_act = scale_exponents['fc1']['act']\n",
    "e_fc2_w = scale_exponents['fc2']['w']\n",
    "\n",
    "print(f\"\\nScale exponents:\")\n",
    "print(f\"  Input: {e_in}\")\n",
    "print(f\"  Conv1: W={e_conv1_w}, Act={e_conv1_act}\")\n",
    "print(f\"  Conv2: W={e_conv2_w}, Act={e_conv2_act}\")\n",
    "print(f\"  FC1: W={e_fc1_w}, Act={e_fc1_act}\")\n",
    "print(f\"  FC2: W={e_fc2_w}\")\n",
    "\n",
    "scratch = np.zeros(65536, dtype=np.int8)\n",
    "timing_buffer = np.zeros(1, dtype=np.uint32)  # ← NEW: Timing array\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\nRunning inference...\\n\")\n",
    "\n",
    "for digit in range(10):\n",
    "    # Reset timing buffer\n",
    "    timing_buffer[0] = 0\n",
    "    \n",
    "    predicted = func(\n",
    "        test_images_int8[digit],\n",
    "        quantized_weights['conv1']['weight'],\n",
    "        quantized_weights['conv1']['bias'],\n",
    "        quantized_weights['conv2']['weight'],\n",
    "        quantized_weights['conv2']['bias'],\n",
    "        quantized_weights['fc1']['weight'],\n",
    "        quantized_weights['fc1']['bias'],\n",
    "        quantized_weights['fc2']['weight'],\n",
    "        quantized_weights['fc2']['bias'],\n",
    "        np.int32(e_in),\n",
    "        np.int32(e_conv1_w), np.int32(e_conv1_act),\n",
    "        np.int32(e_conv2_w), np.int32(e_conv2_act),\n",
    "        np.int32(e_fc1_w), np.int32(e_fc1_act),\n",
    "        np.int32(e_fc2_w),\n",
    "        scratch,\n",
    "        timing_buffer  # ← NEW: Pass timing array\n",
    "    )\n",
    "    \n",
    "    # Read timing from P4\n",
    "    cycles = int(timing_buffer[0])\n",
    "    time_us = cycles / 360.0  # ESP32-P4 @ 360 MHz\n",
    "    time_ms = time_us / 1000.0\n",
    "    \n",
    "    results[digit] = {\n",
    "        'true': digit,\n",
    "        'predicted': predicted,\n",
    "        'correct': (predicted == digit),\n",
    "        'cycles': cycles,\n",
    "        'time_ms': time_ms\n",
    "    }\n",
    "    \n",
    "    status = \"✓\" if predicted == digit else \"✗\"\n",
    "    print(f\"{status} Digit {digit}: Predicted {predicted} | {cycles:,} cycles ({time_ms:.2f} ms)\")\n",
    "\n",
    "correct = sum(1 for r in results.values() if r['correct'])\n",
    "accuracy = 100.0 * correct / len(results)\n",
    "avg_cycles = np.mean([r['cycles'] for r in results.values()])\n",
    "avg_time = np.mean([r['time_ms'] for r in results.values()])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Accuracy: {correct}/10 = {accuracy:.1f}%\")\n",
    "print(f\"✓ Avg cycles: {avg_cycles:,.0f}\")\n",
    "print(f\"✓ Avg time: {avg_time:.2f} ms\")\n",
    "print(f\"✓ Throughput: {1000/avg_time:.1f} fps\")\n",
    "print(f\"✓ Cycles/inference: {avg_cycles:,.0f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.zeros((10, 10), dtype=int)\n",
    "for r in results.values():\n",
    "    confusion[r['true'], r['predicted']] += 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Confusion matrix\n",
    "im = ax1.imshow(confusion, cmap='Blues')\n",
    "ax1.set_xticks(np.arange(10))\n",
    "ax1.set_yticks(np.arange(10))\n",
    "ax1.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'ESP32-P4 Results\\nAccuracy: {accuracy:.1f}%', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax1.text(j, i, confusion[i, j], ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if confusion[i, j] > 0 else \"black\",\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax1)\n",
    "\n",
    "# Timing\n",
    "times = [results[d]['time_ms'] for d in range(10)]\n",
    "colors = ['green' if results[d]['correct'] else 'red' for d in range(10)]\n",
    "\n",
    "ax2.bar(range(10), times, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax2.axhline(avg_time, color='blue', linestyle='--', linewidth=2, label=f'Avg: {avg_time:.2f} ms')\n",
    "ax2.set_xlabel('Digit', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Inference Time', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 Model:\")\n",
    "print(f\"  • Architecture: Conv(1→16) → Conv(16→32) → FC(1568→128) → FC(128→10)\")\n",
    "print(f\"  • Parameters: {total_params:,} bytes ({total_params/1024:.2f} KB)\")\n",
    "print(f\"  • Quantization: INT8 weights + activations + INPUT\")\n",
    "\n",
    "print(\"\\n⚡ Performance:\")\n",
    "print(f\"  • Platform: ESP32-P4 @ 360 MHz (RISC-V)\")\n",
    "print(f\"  • Code size: {func.stats['code_size']/1024:.2f} KB\")\n",
    "print(f\"  • Inference: {avg_time:.2f} ms/image\")\n",
    "print(f\"  • Throughput: {1000/avg_time:.1f} fps\")\n",
    "\n",
    "print(\"\\n🎯 Accuracy:\")\n",
    "print(f\"  • Training (FP32): {history['test_acc'][WARMUP_EPOCHS-1]:.2f}%\")\n",
    "print(f\"  • Training (QAT): {history['test_acc'][-1]:.2f}%\")\n",
    "print(f\"  • On-device (INT8): {accuracy:.1f}%\")\n",
    "print(f\"  • Retention: {accuracy/history['test_acc'][-1]*100:.1f}%\")\n",
    "\n",
    "print(\"\\n🔧 Critical Fixes:\")\n",
    "print(\"  1. ✅ Bias scaled by E_in (not E_in + E_w - E_out)\")\n",
    "print(\"  2. ✅ Input quantization from start\")\n",
    "print(\"  3. ✅ Proper preprocessing match\")\n",
    "print(\"  4. ✅ Individual exponents passed to C\")\n",
    "print(\"  5. ✅ Smart Args for clean interface\")\n",
    "\n",
    "print(\"\\n✨ P4-JIT Advantages:\")\n",
    "print(\"  • 2-3 second deploy (vs 30-60s firmware rebuild)\")\n",
    "print(\"  • No firmware changes needed\")\n",
    "print(\"  • Native RISC-V execution\")\n",
    "print(\"  • Seamless Python ↔ C workflow\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.free()\n",
    "jit.session.device.disconnect()\n",
    "print(\"✓ Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
